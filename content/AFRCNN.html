<html lang="en"><head>
    <meta charset="UTF-8">
    <title></title>
<style id="system" type="text/css">h1,h2,h3,h4,h5,h6,p,blockquote {    margin: 0;    padding: 0;}body {    font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", Arial, sans-serif;    font-size: 13px;    line-height: 18px;    color: #737373;    margin: 10px 13px 10px 13px;}a {    color: #0069d6;}a:hover {    color: #0050a3;    text-decoration: none;}a img {    border: none;}p {    margin-bottom: 9px;}h1,h2,h3,h4,h5,h6 {    color: #404040;    line-height: 36px;}h1 {    margin-bottom: 18px;    font-size: 30px;}h2 {    font-size: 24px;}h3 {    font-size: 18px;}h4 {    font-size: 16px;}h5 {    font-size: 14px;}h6 {    font-size: 13px;}hr {    margin: 0 0 19px;    border: 0;    border-bottom: 1px solid #ccc;}blockquote {    padding: 13px 13px 21px 15px;    margin-bottom: 18px;    font-family:georgia,serif;    font-style: italic;}blockquote:before {    content:"C";    font-size:40px;    margin-left:-10px;    font-family:georgia,serif;    color:#eee;}blockquote p {    font-size: 14px;    font-weight: 300;    line-height: 18px;    margin-bottom: 0;    font-style: italic;}code, pre {    font-family: Monaco, Andale Mono, Courier New, monospace;}code {    background-color: #fee9cc;    color: rgba(0, 0, 0, 0.75);    padding: 1px 3px;    font-size: 12px;    -webkit-border-radius: 3px;    -moz-border-radius: 3px;    border-radius: 3px;}pre {    display: block;    padding: 14px;    margin: 0 0 18px;    line-height: 16px;    font-size: 11px;    border: 1px solid #d9d9d9;    white-space: pre-wrap;    word-wrap: break-word;}pre code {    background-color: #fff;    color:#737373;    font-size: 11px;    padding: 0;}@media screen and (min-width: 768px) {    body {        width: 748px;        margin:10px auto;    }}</style><style id="custom" type="text/css"></style></head>
<body marginheight="0"><h2>A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection</h2>
<p><a href="https://arxiv.org/abs/1704.03414">paper</a>



</p>
<h2>一、论文思想</h2>
<pre><code>训练一个目标检测器，对遮挡和形变鲁棒，目前的主要方法是增加不同场景下的图像数据，但这些数据有时又特别少。作者提出使用对抗生成有遮挡或形变的样本，这些样本对检测器来说识别比较困难，使用这些困难的正样本训练可以增加检测器的鲁棒性。 使用对抗网络生成有遮挡和有形变的两种特征，分别对应网络ASDN和ASTN。使用对抗网络生成有遮挡和有形变的两种特征，分别对应网络ASDN和ASTN。</code></pre>
<h3>1.ASDN</h3>
<ul>
<li>FAST-RCNN中RoI-池化层之后的每个目标proposal卷积特征作为对抗网络的输入，给定一个目标的特征，ASDN尝试生成特征某些部分被dropout的掩码，导致检测器无法识别该物体。</li>
<li><code>ASDN网络初始化</code>:
给定尺寸大小为d×d的特征图X，使用d3×d3的滑动窗，并将滑动窗位置映射到原图，将原图对应位置清零，生成新的特征向量，传入到分类层计算损失，选择具有最大损失的滑动窗，用这个窗口生成二值掩码M(滑动窗位置为1，其余位置为0)，用n个目标proposal生成n对对抗网络的训练样本（x1,M1）,...,(xn,Mn) ，使用二值交叉熵损失训练ASDN: 
<img src="picture\cross_etropy.jpg" alt="cross_extropy"></li>
<li>在前向传播过程中，首先使用ASDN在RoI-池化层之后生成特征掩码，然后使用重要性采样法生成二值掩码，使用该掩码将特征对应部位值清零，修改后的特征继续前向传播计算损失。这个过程生成了困难的特征，用于训练检测器。训练过程流程图如下所示：
<img src="picture\ASDN.jpg" alt="ASDN"></li>
</ul>
<h3>2.ASTN</h3>
<ul>
<li>STN网络包含三部分：定位网络，网格生成器，采样器。定位网络估计出形变的参数（旋转角度、平移距离和缩放因子）。这三个参数作为后两部分的输入，输出是形变后的特征图。论文主要学习定位网络的三个参数。</li>
<li><code>ASTN</code>:
主要关注特征旋转，定位网络包含三层全连接层，前两层是ImageNet预训练的fc6和fc7，训练过程与ASDN类似，ASTN对特征进行形变，使得ASTN将正样本识别成负样本。将特征图划分为4个block，每个block估计四个方向的旋转，增加了任务的复杂度。</li>
<li>两种对抗网络可以相结合，使得检测器更鲁棒，RoI-池化层提取的特征首先传入ASDN丢弃一些激活，之后使用ASTN对特征进行形变，如下图所示：
<img src="picture\ASTNandASDN.jpg" alt="ASTNandASDN"></li>
<li>ASDN 与 ASTN 网络组合架构示意。首先创建遮挡蒙版，随后旋转路径以产生用于训练的例子。</li>
</ul>
<h2>二、训练</h2>
<h3>stage1：training a standard Fast-RCNN</h3>
<pre><code>./experiments/scripts/fast_rcnn_std.sh  [GPU_ID]  VGG16 pascal_voc</code></pre>
<h3>stage2:pre-training stage for the adversarial network</h3>
<pre><code>./experiments/scripts/fast_rcnn_adv_pretrain.sh  [GPU_ID]  VGG16 pascal_voc</code></pre>
<h3>stage3:copy the weights of the above two models to initialize the joint model</h3>
<pre><code>./copy_model.h</code></pre>
<h3>stage4: joint training of the detector and the adversarial network</h3>
<pre><code>./experiments/scripts/fast_rcnn_adv.sh  [GPU_ID]  VGG16 pascal_voc</code></pre>
<h2>三、代码解析</h2>
<h3>1.sigmod交叉熵</h3>
<ul>
<li><p>交叉熵化简：<br><img src="picture/f1.jpg" alt="交叉熵化简">  </p>
<p><img src="picture/f2.jpg" alt="交叉熵化简">  </p>
</li>
<li><p>进一步可化简为：<br><img src="picture/f3.jpg" alt="交叉熵化简">  </p>
</li>
<li><p>代码中使用最终的化简公式：<br><img src="picture/f4.jpg" alt="交叉熵化简">  </p>
</li>
<li><p>对应本文中的代码是：  <strong><em>adversarial-frcnn/lib/roi_data_layer/layer.py</em></strong><a href="https://github.com/philkr/voc-classification/blob/master/src/python_layers.py#L52">源码</a><br><img src="picture/code1.jpg" alt="代码1"></p>
</li>
<li>代码解析：  <h5>1.注意绝对值使用的巧妙之处：</h5>
<em>* lZ  = np.log(1+np.exp(-np.abs(f))) </em> mask
Lz对应化简公式的第二项，其中e的指数项x在两种情况下，均为非正，可以概括为代码中np.exp(-np.abs(f))<h5>2.注意判断语句使用的巧妙之处：</h5>
<em>* ((f&gt;0)-t)</em>f * mask该项对应化简公式的第一项，对应caffe源码为:<br><img src="picture/code2.jpg" alt="代码2"></li>
</ul>
<h2>四、参考链接</h2>
<ul>
<li>caffe网络可视化工具：<a href="http://ethereon.github.io/netscope/#/editor">http://ethereon.github.io/netscope/#/editor</a></li>
<li>交叉熵公式推导：<a href="http://caffecn.cn/?/question/25">http://caffecn.cn/?/question/25</a></li>
<li>交叉熵公式说明：<a href="http://blog.csdn.net/u014114990/article/details/47975739">http://blog.csdn.net/u014114990/article/details/47975739</a></li>
<li>论文代码：<a href="https://github.com/xiaolonw/adversarial-frcnn">https://github.com/xiaolonw/adversarial-frcnn</a>  </li>
</ul>
<h2>关于作者</h2>
<p>edited by <a href="https://github.com/orgs/hustcv/people/galaxy-fangfang">fangfang</a> <a href="https://github.com/orgs/hustcv/people/summerZXH">xiuhong</a>
Edit By <a href="http://mahua.jser.me">MaHua</a></p>
</body></html>